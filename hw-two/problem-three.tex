\documentclass[12pt]{article}
\usepackage{fullpage}
\usepackage{titlesec}
\usepackage{tikz}
\usepackage{amsfonts,amssymb}
\usepackage{amsmath}
\usepackage{comment}
\usetikzlibrary{automata, positioning}
\relpenalty=9999
\binoppenalty=9999

\begin{document}
\pagestyle{plain}
\titleformat{\subsection}[runin]
  {\normalfont\large\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}[runin]
  {\normalfont\large\bfseries}{\thesubsubsection}{1em}{}

\section*{Problem 3a.}

Consider the following randomized algorithm for this problem. Toss a fair coin
for each vertex $v\in V$, if the coin is heads, place $v$ in $U$, otherwise
place $v$ in $W$. Output $U$ and $W$ as the partition of $V$. Then an edge
$(u,w)$ is in the cut C returned by the algorithm if $u\in U$ and $w \in W$.
Let $X_i$ be a binary random variable such that $X_i = 1$ if an edge
$i = (u,w) \in C$ and $X_i = 0$ otherwise. The probability that an edge $i$
is in the cut then is
$$\textbf{Pr}[X_i = 1] = \textbf{Pr}[u \in U \text{ and } w\in W]$$
Since any two edges $u \neq w$ are placed into $U$ and $W$ independently at
random: $$\textbf{Pr}[X_i = 1] = \textbf{Pr}[u \in U]\cdot\textbf{Pr}[w\in W] =
\frac{1}{2}\cdot\frac{1}{2} = \frac{1}{4}$$
Since $X_i$ are binary random variables:
$$\textbf{E}[X_i] = \textbf{Pr}[X_i = 1] = \frac{1}{4}$$
By linearity of expectation:
$$\textbf{E}[X] = \sum^m_{i=1} \textbf{E}[X_i] = \frac{m}{4}$$
Since the upper bound on the optimum solution for a Directed MAX-CUT problem is
$m$ this algorithm returns a 4-approximate solution in expectation.

\section*{Problem 3b.}
For each vertex $v_i \in V$ let $x_i = 1$ if $v_i \in U$ and $x_i = 0$ if
$v_i \in W$. Then for each edge $(i,j) \in E$, $z_{ij}$ can only take a positive,
non-zero value if $v_i \in U$ and $v_j \in W$. If $v_i \in W$ or $v_j \in U$
then one of the first two conditions in the integer linear program will cause
$z_{ij} = 0$. Therefore, the maximation of all $z_{ij}$ occurs only when the number
of edges of the form $(i,j)$ such that $v_i \in U$ and $v_j \in W$ is maximized,
which is exactly the maximum directed cut problem. Specifically the maximization
of $z_{ij}$'s will cause $z_{ij} = 1$ when $(i,j) \in C$ and $z_{ij} = 0$
otherwise. Therefore the summation of all $z_{ij}$'s will be eqaul to the
maximum directed cut in $G$.

\section*{Problem 3c.}
In the LP relaxation of the integer linear program, we can always assign each
$x_i = \frac{1}{2}$ and subsequently each $z_{ij} = \frac{1}{2}$ without
breaking any of the conditions of the linear program, thus making
$\frac{|E|}{2}$ a feasible solution for the linear program and a lower bound on
its maximization for an instance of the problem. Now consider the a complete
directed graph with $2n$ nodes. Then the optimal solution for the problem is
$n^2$. But we know that the LP relaxation can return a solution of size at least
$\frac{|E|}{2}$ where $|E| = 2n\cdot(2n-1)$. So the LP will return a solution of
size at least $\frac{2n\cdot(2n-1)}{2} = 2n^2-n$. So the integrality gap is
$\frac{2n^2-n}{n^2} = 2 - \frac{1}{n}$. This shows that the integrality gap
of the relaxation is at least $2$ because for any gap of size less than $2$
we can show a gap larger than that by picking an arbitrarily large $n$ and
plugging it into the integrality gap we showed which is $2$ at infinity.

\section*{Problem 3d.}
Let $z_{ij}^*$ be the values returned by the LP solution.
First, we state the lemma that $z_{ij}^* = \text{min}(x_i, 1-x_j)$ in the
LP relaxation of the problem. The proof of this is immediate since we attempt
to maximize each $z_{ij}^*$ while bounding it by those two values.
Let $z_{ij}$ be the rounded value of $z_{ij}^*$ after we perform the rounding scheme.
$$\textbf{Pr}[z_{ij} = 1] =
\textbf{Pr}[x_i \in U]\cdot\textbf{Pr}[x_j \notin U] =
(\frac{1}{4} + \frac{x_i}{2}) \cdot (1-(\frac{1}{4} + \frac{x_j}{2})) =
(\frac{1}{4} + \frac{x_i}{2}) \cdot (\frac{3}{4} - \frac{x_j}{2})
$$
There are two cases to consider here, when $x_i \le 1-x_j$ and
$1-x_j \le x_i$. In the first case we can rewrite $x_j$ in terms of $x_i$ as
$x_j \le 1-x_i $ so we get
$$\textbf{Pr}[z_{ij} = 1] \ge 
(\frac{1}{4} + \frac{x_i}{2}) \cdot (\frac{3}{4} - \frac{1-x_i}{2}) =
\left(\frac{1+2x_i}{4}\right)^2
$$
From the above lemma we have that $z_{ij}^* = x_i$ in this case so we get
$$\textbf{Pr}[z_{ij} = 1] \ge \left(\frac{1+2z_{ij}^*}{4}\right)^2$$
Consider now the opposite case, $1-x_j \le x_i$. In this case we can rewrite
$x_i$ in terms of $x_j$ using the inequality directly so we get
$$\textbf{Pr}[z_{ij} = 1] \ge 
\left(\frac{3-2x_j}{4}\right)^2
$$
But again we have that $z_{ij}^* = 1 - x_j$ by the above lemma so we can rewrite
$x_j$ in terms of $z_{ij}^*$ as $x_j = 1 - z_{ij}^*$ so we get
$$\textbf{Pr}[z_{ij} = 1] \ge 
\left(\frac{3-2(1-z_{ij}^*)}{4}\right)^2 =
\left(\frac{1+2z_{ij}^*}{4}\right)^2
$$
So combining both cases we get
$$\textbf{Pr}[z_{ij} = 1] \ge 
2\cdot\left(\frac{1+2z_{ij}^*}{4}\right)^2 \ge
\frac{z_{ij}^*}{2}
$$
Since $z_{ij}$ are $0/1$ random variables we have that $\textbf{E}[z_{ij}] =
\textbf{Pr}[z_{ij} = 1]$. Let $Z^*$ be the value returned by the LP solution and
$Z$ be the value returned by the rounded solution. We have that
$$Z^* = \sum z_{ij}^*$$ and by linearity of expectations we have that
$$\textbf{E}[Z] = \sum \textbf{E}[z_{ij}] = \sum \frac{z_{ij}^*}{2}$$
So we have that the solution returned by the rounding scheme is equal to half of
the LP solution which gives us a 2-approximate solution in expectation.

\end{document}
